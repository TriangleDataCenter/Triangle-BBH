{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit the thread used by numpy \n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\"  \n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import numpy as np\n",
    "import scipy.interpolate as interp \n",
    "try:\n",
    "    import cupy as xp\n",
    "    import cupyx.scipy.interpolate as xinterp\n",
    "    # print(\"has cupy\")\n",
    "except (ImportError, ModuleNotFoundError) as e:\n",
    "    import numpy as xp\n",
    "    import scipy.interpolate as xinterp  \n",
    "    # print(\"no cupy\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['text.usetex'] = True\n",
    "matplotlib.rcParams['font.family'] = 'serif'\n",
    "\n",
    "from Triangle.Constants import *\n",
    "from Triangle.Orbit import * \n",
    "from Triangle.Noise import *\n",
    "from Triangle.FFTTools import *\n",
    "from Triangle.TDI import XYZfromAET, AETfromXYZ\n",
    "\n",
    "from Triangle_BBH.Waveform import * \n",
    "from Triangle_BBH.Response import *\n",
    "from Triangle_BBH.Utils import *\n",
    "from Triangle_BBH.Fisher import *\n",
    "\n",
    "np.random.seed(114514)\n",
    "xp.random.seed(114514)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### orbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orbit model \n",
    "orbit_file = '/media/ps/One Touch/TDCII_Code/Triangle-Simulator/OrbitData/MicroSateOrbitEclipticTCB'\n",
    "orbit = Orbit(OrbitDir=orbit_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### waveform and response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"primary\" # \"primary\" or \"full\"\n",
    "interp_waveform = True # True if the final TDI responses are interpolated from sparse frequency grid, False if calculated at full frequency grid\n",
    "use_gpu = True\n",
    "\n",
    "if mode == \"primary\":\n",
    "    modes = [(2,2)]\n",
    "    approx = \"IMRPhenomD\"\n",
    "elif mode == \"full\": \n",
    "    modes = [(2,2), (2,1), (3,3), (3,2), (4,4), (4,3)]\n",
    "    approx = \"IMRPhenomHM\"\n",
    "else: \n",
    "    raise NotImplementedError(\"mode not implemented\")\n",
    "\n",
    "# initialize  waveform generator \n",
    "WFG = BBHxWaveformGenerator(mode=mode, use_gpu=use_gpu)\n",
    "\n",
    "# initialize response generator \n",
    "FDTDI = BBHxFDTDIResponseGenerator(orbit_class=orbit, waveform_generator=WFG, use_gpu=use_gpu)\n",
    "\n",
    "channel_names = [\"A2\", \"E2\", \"T2\"]\n",
    "\n",
    "# response settings \n",
    "response_kwargs = dict(\n",
    "    modes=modes, \n",
    "    tc_at_constellation=False, \n",
    "    TDIGeneration=\"2nd\", # \"1st\" or \"2nd\"\n",
    "    optimal_combination=True, # True for AET, False for XYZ \n",
    "    output_by_mode=False, \n",
    "    interpolation=interp_waveform,\n",
    "    interpolate_points=1024, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"FDSimulationData.pkl\", \"rb\") as datafile:\n",
    "    datadict = pickle.load(datafile)\n",
    "datadict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = datadict[\"metadata\"][\"t_start\"]\n",
    "tend = datadict[\"metadata\"][\"t_end\"]\n",
    "data_frequency = xp.array(datadict[\"frequency\"])\n",
    "delta_f = data_frequency[1] - data_frequency[0]\n",
    "Tobs = 1. / delta_f\n",
    "data_channels = xp.array(datadict[\"AET\"])\n",
    "fiducial_parameters = datadict[\"parameters\"]\n",
    "\n",
    "response_kwargs[\"tmin\"] = tstart / DAY\n",
    "response_kwargs[\"tmax\"] = tend / DAY \n",
    "\n",
    "response_kwargs, data_frequency.shape, data_channels.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model noise \n",
    "notice that this is a simplified model and the AET channels are only approximately independent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise PSD model \n",
    "PSDfunc = TDIPSDs()\n",
    "\n",
    "# use the median time to calculate armlengths\n",
    "arm_time = (tend + tstart) / 2. \n",
    "arms = dict()\n",
    "for key in MOSA_labels:\n",
    "    arms[key] = orbit.LTTfunctions()[key](arm_time)\n",
    "print(\"arm lengths:\", arms)\n",
    "\n",
    "PSD_channels = xp.array([\n",
    "    PSDfunc.PSD_A2_unequal(data_frequency.get(), arms), \n",
    "    PSDfunc.PSD_E2_unequal(data_frequency.get(), arms), \n",
    "    PSDfunc.PSD_T2_unequal(data_frequency.get(), arms)\n",
    "])\n",
    "\n",
    "# covariance matrix \n",
    "CovMat = xp.array([\n",
    "    [PSD_channels[0], xp.zeros_like(PSD_channels[0]), xp.zeros_like(PSD_channels[0])],\n",
    "    [xp.zeros_like(PSD_channels[0]), PSD_channels[1], xp.zeros_like(PSD_channels[0])],\n",
    "    [xp.zeros_like(PSD_channels[0]), xp.zeros_like(PSD_channels[0]), PSD_channels[2]]\n",
    "]) / 4. / delta_f # (3, 3, Nf)\n",
    "\n",
    "# inverse of covmatrix\n",
    "InvCovMat = xp.linalg.inv(xp.transpose(CovMat, (2, 0, 1))) # (Nf, 3, 3)\n",
    "\n",
    "PSD_channels.shape, InvCovMat.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ich, nch in enumerate(channel_names):\n",
    "    plt.loglog(data_frequency.get(), np.abs(data_channels[ich].get()), label=nch, linewidth=1)\n",
    "    plt.loglog(data_frequency.get(), np.sqrt(PSD_channels[ich] / 2. / delta_f).get(), color=\"grey\")\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Fourier transform (1/Hz)\")\n",
    "plt.grid(linestyle=\":\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use A, E channels only \n",
    "set $C^{-1}_{T_2 T_2} \\equiv 0$ to eliminate the contribution of $T_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InvCovMat[:, 2, 2] *= 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Like = Likelihood(\n",
    "    response_generator=FDTDI, \n",
    "    frequency=data_frequency, \n",
    "    data=data_channels, \n",
    "    invserse_covariance_matrix=InvCovMat, \n",
    "    response_parameters=response_kwargs, \n",
    "    use_gpu=use_gpu,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run MCMC Sampling \n",
    "search with the full likelihood from a broad prior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eryn.ensemble import EnsembleSampler\n",
    "from eryn.state import State\n",
    "from eryn.prior import ProbDistContainer, uniform_dist\n",
    "from eryn.utils import TransformContainer\n",
    "from eryn.moves import GaussianMove, StretchMove, CombineMove\n",
    "from eryn.utils.utility import groups_from_inds\n",
    "from eryn.backends import HDFBackend\n",
    "from eryn.utils import SearchConvergeStopping\n",
    "\n",
    "from corner import corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set hyper parameters\n",
    "ndim = 11 # dimension of paramters \n",
    "nwalkers = 150 # number of random walkers, limited by the vRAM of my 4080S, use fewer (e.g. 100) to speed up and more (e.g. 200) to get more smooth posterior \n",
    "ntemps = 10 # number of temperatures used in parallel tempering \n",
    "temps = np.array(list(np.power(2., np.arange(ntemps - 1))) + [np.infty]) \n",
    "betas = 1. / temps \n",
    "tempering_kwargs=dict(betas=betas)\n",
    "\n",
    "mcmc_moves = StretchMove(a=2) # mcmc move \n",
    "\n",
    "stop = None \n",
    "\n",
    "# set priors \n",
    "lim_lgMc = [5.5, 6.5]\n",
    "lim_q = [0.1, 0.999]\n",
    "lim_chiz1 = [-0.99, 0.99]\n",
    "lim_chiz2 = [-0.99, 0.99]\n",
    "lim_tc = [fiducial_parameters[\"coalescence_time\"] - 500/DAY, fiducial_parameters[\"coalescence_time\"] + 500/DAY] # assume a preliminary search step to locate the merger within 1000s\n",
    "lim_phic = [0, TWOPI]\n",
    "lim_lgD = [3.5, 5.5]\n",
    "lim_cosinc = [-1, 1]\n",
    "lim_lam = [0, TWOPI]\n",
    "lim_sinbeta = [-1, 1]\n",
    "lim_psi = [0, PI]\n",
    "\n",
    "lims = np.array([lim_lgMc, lim_q, lim_chiz1, lim_chiz2, lim_tc, lim_phic, lim_lgD, lim_cosinc, lim_lam, lim_sinbeta, lim_psi])\n",
    "lower_lims = lims[:, 0]\n",
    "upper_lims = lims[:, 1]\n",
    "\n",
    "priors_in = {i: uniform_dist(lims[i][0], lims[i][1]) for i in range(ndim)}\n",
    "priors = ProbDistContainer(priors_in)\n",
    "priors.use_cupy = False\n",
    "\n",
    "lims "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eryn_like(params): \n",
    "    \"\"\"params: numpy array of shape (Nevents, Nparams)\"\"\"\n",
    "    return Like.full_log_like_vectorized(np.transpose(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init_ensemble = EnsembleSampler(\n",
    "#     nwalkers,\n",
    "#     ndim,\n",
    "#     eryn_like, \n",
    "#     priors,\n",
    "#     args=[],\n",
    "#     tempering_kwargs=tempering_kwargs,\n",
    "#     stopping_fn=stop,\n",
    "#     stopping_iterations=10,\n",
    "#     moves=mcmc_moves,\n",
    "#     vectorize=True,\n",
    "# )\n",
    "\n",
    "# filename='MCMCResults/FullLogLike.h5'\n",
    "# backend = HDFBackend(filename)\n",
    "# backend.reset(nwalkers=nwalkers, ndims=ndim, ntemps=ntemps, moves=init_ensemble.backend.move_keys)\n",
    "# print('args of the backend =', backend.reset_args)\n",
    "# print('move keys =', backend.move_keys)\n",
    "# print('Initialization flag of backend =', backend.initialized)\n",
    "\n",
    "\n",
    "# ensemble = EnsembleSampler(\n",
    "#     nwalkers,\n",
    "#     ndim,\n",
    "#     eryn_like, \n",
    "#     priors,\n",
    "#     args=[],\n",
    "#     tempering_kwargs=tempering_kwargs,\n",
    "#     stopping_fn=stop,\n",
    "#     stopping_iterations=10,\n",
    "#     moves=init_ensemble.moves,\n",
    "#     backend=backend,\n",
    "#     vectorize=True,\n",
    "# )\n",
    "\n",
    "\n",
    "ensemble = EnsembleSampler(\n",
    "    nwalkers,\n",
    "    ndim,\n",
    "    eryn_like, \n",
    "    priors,\n",
    "    args=[],\n",
    "    tempering_kwargs=tempering_kwargs,\n",
    "    stopping_fn=stop,\n",
    "    stopping_iterations=10,\n",
    "    moves=mcmc_moves,\n",
    "    vectorize=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomize starting positions throughout prior\n",
    "coords = priors.rvs(size=(ntemps, nwalkers,))\n",
    "print(coords.shape)\n",
    "\n",
    "thin_by = 100 \n",
    "burn = 0\n",
    "nsteps = int(100000 / thin_by) # should be more than enough \n",
    "\n",
    "ensemble.stopping_fn = None\n",
    "\n",
    "out = ensemble.run_mcmc(coords, nsteps, burn=burn, progress=True, thin_by=thin_by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # resume run after the run is stopped \n",
    "# thin_by =100\n",
    "# burn = 0\n",
    "# nsteps = int(100000 / thin_by) # this should be far more than enough \n",
    "\n",
    "# out = ensemble.run_mcmc(ensemble.get_last_sample(), nsteps, burn=burn, progress=True, thin_by=thin_by)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show moves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    'log_chirp_mass',\n",
    "    'mass_ratio',\n",
    "    'spin_1z',\n",
    "    'spin_2z',\n",
    "    'coalescence_time',\n",
    "    'coalescence_phase',\n",
    "    'log_luminosity_distance',\n",
    "    'cos_inclination',\n",
    "    'longitude',\n",
    "    'sin_latitude',\n",
    "    'psi'\n",
    "    ]\n",
    "truths = ParamDict2ParamArr(fiducial_parameters)\n",
    "\n",
    "truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thin = 10\n",
    "burnin = 0\n",
    "len_chain = len(ensemble.get_chain(thin=thin, discard=burnin)['model_0'][:, 0, 0, :, 0])\n",
    "\n",
    "fig, ax = plt.subplots(ndim, 1)\n",
    "fig.set_size_inches(10, 3*ndim)\n",
    "for i in range(ndim):     \n",
    "    for walk in range(20): # plot 20 walkers \n",
    "        ax[i].plot(ensemble.get_chain(thin=thin, discard=burnin)['model_0'][:, 0, walk, 0, i])\n",
    "        ax[i].hlines(truths[i], 0, len_chain, color='k', linestyle='-.', linewidth=0.8)\n",
    "    ax[i].set_ylabel(labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corner plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burnin=500\n",
    "thin = 10\n",
    "\n",
    "samp = ensemble.get_chain(discard=burnin, thin=thin)['model_0'][:, 0, :, :, :].reshape(-1, ndim)\n",
    "print(\"sample shape:\", samp.shape)\n",
    "\n",
    "plt.figure()\n",
    "corner(\n",
    "    samp, bins=50, color=BLUE, \n",
    "    labels=labels, label_kwargs={'fontsize': 14}, \n",
    "    truths=truths, truth_color=RED, \n",
    "    quantiles=[0.16, 0.5, 0.84],\n",
    "    show_titles=True, title_kwargs={'fontsize':14},\n",
    "    levels = (1. - np.exp(-1.**2/2), 1. - np.exp(-2.**2/2), 1. - np.exp(-3.**2/2)),\n",
    "    smooth=0.9, # default for bilby: smooth = 0.9, bins = 50 \n",
    "    plot_density=True, # whether to show the density of samples with colors \n",
    "    plot_datapoints=False, # whether to plot individual data points \n",
    "    fill_contours=True, # whether to fill the corners \n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "triangle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
