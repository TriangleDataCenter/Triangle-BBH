{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit the thread used by numpy \n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\"  \n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import numpy as np\n",
    "import scipy.interpolate as interp \n",
    "try:\n",
    "    import cupy as xp\n",
    "    import cupyx.scipy.interpolate as xinterp\n",
    "    # print(\"has cupy\")\n",
    "except (ImportError, ModuleNotFoundError) as e:\n",
    "    import numpy as xp\n",
    "    import scipy.interpolate as xinterp  \n",
    "    # print(\"no cupy\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib\n",
    "# matplotlib.rcParams['text.usetex'] = True\n",
    "# matplotlib.rcParams['font.family'] = 'serif'\n",
    "\n",
    "from Triangle.Constants import *\n",
    "from Triangle.Orbit import * \n",
    "from Triangle.Noise import *\n",
    "from Triangle.FFTTools import *\n",
    "from Triangle.TDI import XYZfromAET, AETfromXYZ\n",
    "\n",
    "from Triangle_BBH.Waveform import * \n",
    "from Triangle_BBH.Response import *\n",
    "from Triangle_BBH.Utils import *\n",
    "from Triangle_BBH.Fisher import *\n",
    "\n",
    "np.random.seed(114514)\n",
    "xp.random.seed(114514)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"FDSimulationData.pkl\", \"rb\") as datafile:\n",
    "    datadict = pickle.load(datafile)\n",
    "datadict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frequency = xp.array(datadict[\"frequency\"])\n",
    "delta_f = data_frequency[1] - data_frequency[0]\n",
    "Tobs = 1. / delta_f\n",
    "\n",
    "data_channels = xp.array(datadict[\"AET\"])\n",
    "\n",
    "fiducial_parameters = datadict[\"parameters\"]\n",
    "\n",
    "response_kwargs = datadict[\"response_kwargs\"]\n",
    "\n",
    "data_frequency.shape, data_channels.shape, response_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### orbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orbit model \n",
    "orbit_file = '/home/TFDAnalysls_new/Data/OrbitData/MicroSateOrbitEclipticTCB'\n",
    "orbit = Orbit(OrbitDir=orbit_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### waveform and response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"primary\"\n",
    "use_gpu = True \n",
    "\n",
    "# initialize  waveform generator \n",
    "WFG = BBHxWaveformGenerator(mode=mode, use_gpu=use_gpu)\n",
    "\n",
    "# initialize response generator \n",
    "FDTDI = BBHxFDTDIResponseGenerator(orbit_class=orbit, waveform_generator=WFG, use_gpu=use_gpu)\n",
    "\n",
    "channel_names = [\"A2\", \"E2\", \"T2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model noise \n",
    "notice that this is a simplified model and the AET channels are only approximately independent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise PSD model \n",
    "PSDfunc = TDIPSDs()\n",
    "\n",
    "# use the median time to calculate armlengths\n",
    "arm_time = (response_kwargs[\"tmin\"] + response_kwargs[\"tmax\"]) / 2. * DAY \n",
    "arms = dict()\n",
    "for key in MOSA_labels:\n",
    "    arms[key] = orbit.LTTfunctions()[key](arm_time)\n",
    "print(\"arm time (day):\", arm_time / DAY)\n",
    "print(\"arm lengths:\", arms)\n",
    "\n",
    "PSD_channels = xp.array([\n",
    "    PSDfunc.PSD_A2_unequal(data_frequency.get(), arms), \n",
    "    PSDfunc.PSD_E2_unequal(data_frequency.get(), arms), \n",
    "    PSDfunc.PSD_T2_unequal(data_frequency.get(), arms)\n",
    "])\n",
    "\n",
    "# covariance matrix \n",
    "CovMat = xp.array([\n",
    "    [PSD_channels[0], xp.zeros_like(PSD_channels[0]), xp.zeros_like(PSD_channels[0])],\n",
    "    [xp.zeros_like(PSD_channels[0]), PSD_channels[1], xp.zeros_like(PSD_channels[0])],\n",
    "    [xp.zeros_like(PSD_channels[0]), xp.zeros_like(PSD_channels[0]), PSD_channels[2]]\n",
    "]) / 4. / delta_f # (3, 3, Nf)\n",
    "\n",
    "# inverse of covmatrix\n",
    "InvCovMat = xp.linalg.inv(xp.transpose(CovMat, (2, 0, 1))) # (Nf, 3, 3)\n",
    "\n",
    "PSD_channels.shape, InvCovMat.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ich, nch in enumerate(channel_names):\n",
    "    plt.loglog(data_frequency.get(), np.abs(data_channels[ich].get()), label=nch, linewidth=1)\n",
    "    plt.loglog(data_frequency.get(), np.sqrt(PSD_channels[ich] / 2. / delta_f).get(), color=\"grey\")\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Fourier transform (1/Hz)\")\n",
    "plt.grid(linestyle=\":\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use A, E channels only \n",
    "set $C^{-1}_{T_2 T_2} \\equiv 0$ to eliminate the contribution of $T_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InvCovMat[:, 2, 2] *= 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Like = Likelihood(\n",
    "    response_generator=FDTDI, \n",
    "    frequency=data_frequency, \n",
    "    data=data_channels, \n",
    "    invserse_covariance_matrix=InvCovMat, \n",
    "    response_parameters=response_kwargs, \n",
    "    use_gpu=use_gpu,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test if likelihood peaks at truths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiducial_param_arr = ParamDict2ParamArr(fiducial_parameters)\n",
    "\n",
    "N_test=101\n",
    "test_idx = 4 # tc \n",
    "test_params = np.linspace(-1e-3, 1e-3, N_test) + fiducial_param_arr[test_idx]\n",
    "\n",
    "tmp_params = np.zeros((11, N_test))\n",
    "for i_test in range(N_test):\n",
    "    tmp_params[:, i_test] = fiducial_param_arr.copy()\n",
    "    tmp_params[test_idx][i_test] = test_params[i_test]\n",
    "test_lls_vec = Like.full_log_like_vectorized(tmp_params)\n",
    "plt.plot(test_params, test_lls_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run MCMC Sampling \n",
    "\n",
    "the aim is to compare the posteriors of full and heterodyned likelihoods, so we choose ideal priors and starting points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eryn.ensemble import EnsembleSampler\n",
    "from eryn.state import State\n",
    "from eryn.prior import ProbDistContainer, uniform_dist\n",
    "from eryn.utils import TransformContainer\n",
    "from eryn.moves import GaussianMove, StretchMove, CombineMove\n",
    "from eryn.utils.utility import groups_from_inds\n",
    "from eryn.backends import HDFBackend\n",
    "from eryn.utils import SearchConvergeStopping\n",
    "\n",
    "from corner import corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [r\"${\\rm lg}\\mathcal{M}_{c,z}$\", r\"$q$\", r\"$\\chi_{z,1}$\", r\"$\\chi_{z,2}$\", r\"$t_c$\", r\"$\\varphi_c$\", r\"${\\rm lg} D_L$\", r\"$\\cos \\iota$\", r\"$\\lambda$\", r\"$\\sin \\beta$\", r\"$\\psi$\"]\n",
    "\n",
    "truths = ParamDict2ParamArr(fiducial_parameters)\n",
    "\n",
    "truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set hyper parameters\n",
    "ndim = 11 # dimension of paramters \n",
    "nwalkers = 100 # number of random walkers, limited by the vRAM of my 4080S, use fewer (e.g. 100) to speed up and more (e.g. 400) to get more smooth posterior \n",
    "ntemps = 10 # number of temperatures used in parallel tempering \n",
    "temps = np.array(list(np.power(2., np.arange(ntemps - 1))) + [np.infty]) \n",
    "betas = 1. / temps \n",
    "tempering_kwargs=dict(betas=betas)\n",
    "\n",
    "mcmc_moves = StretchMove(a=2) # mcmc move \n",
    "\n",
    "stop = None \n",
    "\n",
    "# set priors \n",
    "lim_lgMc = [5.5, 6.5]\n",
    "lim_q = [0.1, 0.999]\n",
    "lim_chiz1 = [-0.99, 0.99]\n",
    "lim_chiz2 = [-0.99, 0.99]\n",
    "lim_tc = [fiducial_parameters[\"coalescence_time\"] - 500/DAY, fiducial_parameters[\"coalescence_time\"] + 500/DAY] # assume a preliminary search step to locate the merger within 1000s\n",
    "lim_phic = [0, TWOPI]\n",
    "lim_lgD = [3.5, 5.5]\n",
    "lim_cosinc = [-1, 1]\n",
    "lim_lam = [0, TWOPI]\n",
    "lim_sinbeta = [-1, 1]\n",
    "lim_psi = [0, PI]\n",
    "\n",
    "lims = np.array([lim_lgMc, lim_q, lim_chiz1, lim_chiz2, lim_tc, lim_phic, lim_lgD, lim_cosinc, lim_lam, lim_sinbeta, lim_psi])\n",
    "lower_lims = lims[:, 0]\n",
    "upper_lims = lims[:, 1]\n",
    "\n",
    "priors_in = {i: uniform_dist(lims[i][0], lims[i][1]) for i in range(ndim)}\n",
    "priors = ProbDistContainer(priors_in)\n",
    "priors.use_cupy = False\n",
    "\n",
    "# set starting range \n",
    "start_lims = np.array(truths)[:, np.newaxis] + np.array([-1e-3, 1e-3])\n",
    "start_priors_in = {i: uniform_dist(start_lims[i][0], start_lims[i][1]) for i in range(ndim)}\n",
    "start_priors = ProbDistContainer(start_priors_in)\n",
    "start_priors.use_cupy = False\n",
    "\n",
    "lims, start_lims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eryn_like(params): \n",
    "    \"\"\"params: numpy array of shape (Nevents, Nparams)\"\"\"\n",
    "    return Like.full_log_like_vectorized(np.transpose(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init_ensemble = EnsembleSampler(\n",
    "#     nwalkers,\n",
    "#     ndim,\n",
    "#     eryn_like, \n",
    "#     priors,\n",
    "#     args=[],\n",
    "#     tempering_kwargs=tempering_kwargs,\n",
    "#     stopping_fn=stop,\n",
    "#     stopping_iterations=10,\n",
    "#     moves=mcmc_moves,\n",
    "#     vectorize=True,\n",
    "# )\n",
    "\n",
    "# filename='MCMCResults/FullLogLike.h5'\n",
    "# backend = HDFBackend(filename)\n",
    "# backend.reset(nwalkers=nwalkers, ndims=ndim, ntemps=ntemps, moves=init_ensemble.backend.move_keys)\n",
    "# print('args of the backend =', backend.reset_args)\n",
    "# print('move keys =', backend.move_keys)\n",
    "# print('Initialization flag of backend =', backend.initialized)\n",
    "\n",
    "\n",
    "# ensemble = EnsembleSampler(\n",
    "#     nwalkers,\n",
    "#     ndim,\n",
    "#     eryn_like, \n",
    "#     priors,\n",
    "#     args=[],\n",
    "#     tempering_kwargs=tempering_kwargs,\n",
    "#     stopping_fn=stop,\n",
    "#     stopping_iterations=10,\n",
    "#     moves=init_ensemble.moves,\n",
    "#     backend=backend,\n",
    "#     vectorize=True,\n",
    "# )\n",
    "\n",
    "\n",
    "ensemble = EnsembleSampler(\n",
    "    nwalkers,\n",
    "    ndim,\n",
    "    eryn_like, \n",
    "    priors,\n",
    "    args=[],\n",
    "    tempering_kwargs=tempering_kwargs,\n",
    "    stopping_fn=stop,\n",
    "    stopping_iterations=10,\n",
    "    moves=mcmc_moves,\n",
    "    vectorize=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomize starting positions throughout prior\n",
    "coords = start_priors.rvs(size=(ntemps, nwalkers,))\n",
    "print(coords.shape)\n",
    "\n",
    "thin_by = 100 \n",
    "burn = 0\n",
    "nsteps = int(100000 / thin_by) # should be more than enough \n",
    "\n",
    "ensemble.stopping_fn = None\n",
    "\n",
    "out = ensemble.run_mcmc(coords, nsteps, burn=burn, progress=True, thin_by=thin_by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resume run after the run is stopped \n",
    "thin_by =100\n",
    "burn = 0\n",
    "nsteps = int(100000 / thin_by) # this should be far more than enough \n",
    "\n",
    "out = ensemble.run_mcmc(ensemble.get_last_sample(), nsteps, burn=burn, progress=True, thin_by=thin_by)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show moves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thin = 10\n",
    "burnin = 0\n",
    "len_chain = len(ensemble.get_chain(thin=thin, discard=burnin)['model_0'][:, 0, 0, :, 0])\n",
    "\n",
    "plt.figure()\n",
    "fig, ax = plt.subplots(ndim, 1)\n",
    "fig.set_size_inches(10, 3*ndim)\n",
    "for i in range(ndim):     \n",
    "    for walk in range(20): # plot 20 walkers \n",
    "        ax[i].plot(ensemble.get_chain(thin=thin, discard=burnin)['model_0'][:, 0, walk, 0, i])\n",
    "        ax[i].hlines(truths[i], 0, len_chain, color='k', linestyle='-.', linewidth=0.8)\n",
    "    ax[i].set_ylabel(labels[i])\n",
    "plt.savefig(\"/home/Triangle-BBH/Examples/MCMC_trajectory_full.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corner plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burnin=1500\n",
    "thin = 10\n",
    "\n",
    "samp = ensemble.get_chain(discard=burnin, thin=thin)['model_0'][:, 0, :, :, :].reshape(-1, ndim)\n",
    "print(\"sample shape:\", samp.shape)\n",
    "\n",
    "plt.figure()\n",
    "corner(\n",
    "    samp, bins=50, color=BLUE, \n",
    "    labels=labels, label_kwargs={'fontsize': 14}, \n",
    "    # range=lims,\n",
    "    truths=truths, truth_color=RED, \n",
    "    quantiles=[0.16, 0.5, 0.84],\n",
    "    show_titles=True, title_kwargs={'fontsize':14},\n",
    "    levels = (1. - np.exp(-1.**2/2), 1. - np.exp(-2.**2/2), 1. - np.exp(-3.**2/2)),\n",
    "    smooth=0.9, # default for bilby: smooth = 0.9, bins = 50 \n",
    "    plot_density=True, # whether to show the density of samples with colors \n",
    "    plot_datapoints=False, # whether to plot individual data points \n",
    "    fill_contours=True, # whether to fill the corners \n",
    "    );\n",
    "plt.savefig(\"/home/Triangle-BBH/Examples/MCMC_corner_full.jpg\")\n",
    "np.save(\"chain_full.npy\", samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "triangle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
